{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File with the reviews database\n",
    "file = '/Users/gkhanna/Downloads/reviews_Home_and_Kitchen_5.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/gkhanna/Google Drive/210Capstone/code/InsightsFromReviews/app/ai',\n",
       " '/Users/gkhanna/anaconda3/lib/python37.zip',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/lib-dynload',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages/aeosa',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/gkhanna/.ipython']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\r\n",
      "Version: 1.14.0\r\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author: Google Inc.\r\n",
      "Author-email: packages@tensorflow.org\r\n",
      "License: Apache 2.0\r\n",
      "Location: /Users/gkhanna/anaconda3/lib/python3.7/site-packages\r\n",
      "Requires: wheel, termcolor, astor, numpy, absl-py, google-pasta, keras-preprocessing, tensorboard, tensorflow-estimator, gast, six, protobuf, wrapt, grpcio, keras-applications\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip3 show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages'\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/gkhanna/Google Drive/210Capstone/code/InsightsFromReviews/app/ai',\n",
       " '/Users/gkhanna/anaconda3/lib/python37.zip',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/lib-dynload',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages/aeosa',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/gkhanna/.ipython',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gkhanna/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.tokens.span.Span size changed, may indicate binary incompatibility. Expected 72 from C header, got 80 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from insights import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insights import languageUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insights import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10579it [00:00, 105783.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000 Reviews written to the dictionary \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load reviews into a dictionary\n",
    "file_d = features.loadFromDb(file, count = 12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(len(file_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewerID': 'APYOBQE6M18AA',\n",
       " 'asin': '0615391206',\n",
       " 'reviewerName': 'Martin Schwartz',\n",
       " 'helpful': [0, 0],\n",
       " 'reviewText': 'My daughter wanted this book and the price on Amazon was the best.  She has already tried one recipe a day after receiving the book.  She seems happy with it.',\n",
       " 'overall': 5.0,\n",
       " 'summary': 'Best Price',\n",
       " 'unixReviewTime': 1382140800,\n",
       " 'reviewTime': '10 19, 2013'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ASIN corresponding to the Iron Skillet\n",
    "# pl = 'B00006JSUA'\n",
    "# pl = 'B000QFDNP8'\n",
    "pl = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:01<00:00, 10676.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and Classified 12000 Reviews\n",
      "11116 Positive reviews\n",
      "884 Negative reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_sent, reviews_pos_sent, reviews_neg_sent, sum_sent, sum_pos_sent, sum_neg_sent = summary.loadTolistsAndClassify(file_d, pl, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(sum_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_start_ not the best _end_'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_neg_sent[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bag tore with almost nothing in it   just caught the corner of a small cracker box and that was that  pretty disappointed '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_neg_sent[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this book is a must have if you get a zoku  which i also highly recommend   there is a large variety of recipes from simple  to fancy  the flavor combos are creative  and it gives you ideas for decorating the pops too  they turn out as beautiful as they are tasty  after reading it you will be inspired to create your own recipes too '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sent[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_start_ creative combos _end_'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_sent[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word counts in reviews and summaries\n",
    "We'll get another validation of this after tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_word_count = []\n",
    "sum_word_count = []\n",
    "\n",
    "for i in reviews_sent:\n",
    "      reviews_word_count.append(len(i.split()))\n",
    "\n",
    "for i in sum_sent:\n",
    "      sum_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'Reviews':reviews_word_count, 'summary':sum_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize: text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB_SIZE = 800\n",
    "# tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've already cleaned up the data\n",
    "# Though we could use this for cleaning also\n",
    "reviews_tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20490"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_tokenizer = Tokenizer()\n",
    "r_tokenizer.fit_on_texts(reviews_sent)\n",
    "reviews_sequences = r_tokenizer.texts_to_sequences(reviews_sent)\n",
    "reviews_word_index = r_tokenizer.word_index\n",
    "len(reviews_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4479"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_tokenizer = Tokenizer()\n",
    "s_tokenizer.fit_on_texts(sum_sent)\n",
    "summary_sequences = s_tokenizer.texts_to_sequences(sum_sent)\n",
    "sum_word_index = s_tokenizer.word_index\n",
    "len(sum_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20491"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_vocab_size = len(reviews_word_index) + 1\n",
    "reviews_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4480"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_vocab_size = len(sum_word_index) + 1\n",
    "sum_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max len of the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1978"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_reviews_seq_len = max([len(seq) for seq in reviews_sequences])\n",
    "max_reviews_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_summary_seq_len = max([len(seq) for seq in summary_sequences])\n",
    "max_summary_seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB_SIZE = len(reviews_word_index) - 10\n",
    "# VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_word_index_vsize = {}\n",
    "# counter = 0\n",
    "# for word in reviews_word_index.keys():\n",
    "#     if reviews_word_index[word] == 0:\n",
    "#         print(\"found 0!\")\n",
    "#         break\n",
    "#     if reviews_word_index[word] > VOCAB_SIZE:\n",
    "#         continue\n",
    "#     else:\n",
    "#         reviews_word_index_vsize[word] = reviews_word_index[word]\n",
    "#         counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(reviews_word_index_vsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_word_index_vsize = {}\n",
    "# counter = 0\n",
    "# for word in sum_word_index.keys():\n",
    "#     if sum_word_index[word] == 0:\n",
    "#         print(\"found 0!\")\n",
    "#         break\n",
    "#     if sum_word_index[word] > VOCAB_SIZE:\n",
    "#         continue\n",
    "#     else:\n",
    "#         sum_word_index_vsize[word] = sum_word_index[word]\n",
    "#         counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sum_word_index_vsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# MAX_LEN = max_reviews_seq_len\n",
    "pad_reviews_sequences = pad_sequences(reviews_sequences, maxlen=max_reviews_seq_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 1978\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_sequences[0]), len(pad_reviews_sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 17 705 310 ...   0   0   0]\n",
      " [  2  77   9 ...   0   0   0]\n",
      " [ 92   7  57 ...   0   0   0]\n",
      " ...\n",
      " [  9   7   5 ...   0   0   0]\n",
      " [  9 762 360 ...   0   0   0]\n",
      " [  2  25  82 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(pad_reviews_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 1978)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_reviews_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sum_sequences = pad_sequences(summary_sequences, maxlen=max_summary_seq_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 45\n"
     ]
    }
   ],
   "source": [
    "print(len(summary_sequences[0]), len(pad_sum_sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 45)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sum_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = np.zeros((num_samples, max_reviews_seq_len), dtype='float32')\n",
    "encoder_inputs.shape\n",
    "\n",
    "for i, seqs in enumerate(pad_reviews_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        encoder_inputs[i, j] = seq\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 1978)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder_inputs = np.zeros((num_samples, max_summary_seq_len), dtype='float32')\n",
    "decoder_inputs.shape\n",
    "        \n",
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        decoder_inputs[i, j] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 45)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 45, 4480)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs = np.zeros((num_samples, max_summary_seq_len, sum_vocab_size), dtype='float32')\n",
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        if j > 0:\n",
    "            decoder_outputs[i, j-1, seq] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 45, 4480)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('/Users/gkhanna/Downloads/glove.6B/glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['start'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix_creater(embedding_dimension, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dimension))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20491, 100)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_embedding_matrix = embedding_matrix_creater(EMBEDDING_DIM, word_index=reviews_word_index)\n",
    "reviews_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20491"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4480, 100)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_embedding_matrix = embedding_matrix_creater(EMBEDDING_DIM, word_index=sum_word_index)\n",
    "sum_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0730 16:09:32.464920 140736209961856 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0730 16:09:32.466200 140736209961856 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0730 16:09:32.487793 140736209961856 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as k\n",
    "k.clear_session()\n",
    "k.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import initializers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,LSTM,Dropout,Input,Activation,Add,concatenate, Embedding, RepeatVector\n",
    "from keras.layers.advanced_activations import LeakyReLU,PReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insights.attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "\n",
    "# MAX_LEN = 1000\n",
    "# VOCAB_SIZE = len(sum_embedding_matrix)\n",
    "# EMBEDDING_DIM = 200\n",
    "HIDDEN_UNITS = 100\n",
    "# VOCAB_SIZE = VOCAB_SIZE + 1\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 5\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_embedding_layer = Embedding(input_dim = reviews_vocab_size, \n",
    "#                                     output_dim = EMBEDDING_DIM,\n",
    "#                                     input_length = max_reviews_seq_len,\n",
    "#                                     weights = [reviews_embedding_matrix],\n",
    "#                                     trainable = False)\n",
    "\n",
    "# decoder_embedding_layer = Embedding(input_dim = sum_vocab_size, \n",
    "#                                     output_dim = EMBEDDING_DIM,\n",
    "#                                     input_length = max_summary_seq_len,\n",
    "#                                     weights = [sum_embedding_matrix],\n",
    "#                                     trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_embedding_layer = Embedding(input_dim = reviews_vocab_size, \n",
    "                                    output_dim = EMBEDDING_DIM,\n",
    "                                    weights = [reviews_embedding_matrix],\n",
    "                                    trainable = False)\n",
    "\n",
    "decoder_embedding_layer = Embedding(input_dim = sum_vocab_size, \n",
    "                                    output_dim = EMBEDDING_DIM,\n",
    "                                    weights = [sum_embedding_matrix],\n",
    "                                    trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4480"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0730 16:09:32.555334 140736209961856 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0730 16:09:32.567779 140736209961856 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1978)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1978, 100)    2049100     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 1978, 100),  80400       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 100)    448000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 1978, 100),  80400       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 100),  80400       embedding_2[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 4480)   452480      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,190,780\n",
      "Trainable params: 693,680\n",
      "Non-trainable params: 2,497,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## # encoder\n",
    "encoder_inputs = Input(shape=(max_reviews_seq_len, ), dtype = 'int32',)\n",
    "encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "# LSTM 1\n",
    "encoder_LSTM1 = LSTM(HIDDEN_UNITS, return_sequences = True, return_state = True)\n",
    "encoder_output1, state_h1, state_c1 = encoder_LSTM1(encoder_embedding)\n",
    "\n",
    "# LSTM 2\n",
    "encoder_LSTM2 = LSTM(HIDDEN_UNITS, return_sequences = True, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder_LSTM2(encoder_output1)\n",
    "\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# decoder\n",
    "# decoder_inputs = Input(shape=(max_summary_seq_len, ), dtype = 'int32')\n",
    "decoder_inputs = Input(shape=(None, ), dtype = 'int32')\n",
    "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# Decoder LSTM with encoder_states as the initial state\n",
    "decoder_LSTM = LSTM(HIDDEN_UNITS, return_sequences = True, return_state = True)\n",
    "decoder_outputs, state_d_h, state_d_c = decoder_LSTM(decoder_embedding, initial_state = [state_h, state_c])\n",
    "\n",
    "# Dense Layer\n",
    "decoder_dense = TimeDistributed(Dense(units=sum_vocab_size, activation=\"softmax\"))\n",
    "decoder_outputs = decoder_dense(decoder_outputs) # SUM_VOCAB_SIZE, sum_embedding_matrix.shape[1]\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0730 16:09:33.541301 140736209961856 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(pad_sum_sequences)\n",
    "decoder_output_data = np.zeros((num_samples, max_summary_seq_len, sum_vocab_size), dtype=\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 45)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sum_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 45, 4480)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        if j > 0:\n",
    "            decoder_output_data[i][j - 1][seq] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train, reviews_test, sum_train, sum_test = train_test_split(pad_reviews_sequences, pad_sum_sequences, test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num = reviews_train.shape[0]\n",
    "train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 1978)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 77, 87, ...,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 1978)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 45)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 734, 101,  24,  18, 583,  15, 553,   2,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 45)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = decoder_output_data[:train_num]\n",
    "target_test = decoder_output_data[train_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 45, 4480)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 45, 4480)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 45, 4480)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0730 16:09:36.131860 140736209961856 deprecation.py:323] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/20\n",
      "9600/9600 [==============================] - 17710s 2s/step - loss: 0.6838 - acc: 0.9067 - val_loss: 0.6525 - val_acc: 0.9091\n",
      "Epoch 2/20\n",
      "9600/9600 [==============================] - 6298s 656ms/step - loss: 0.5872 - acc: 0.9128 - val_loss: 0.6407 - val_acc: 0.9105\n",
      "Epoch 3/20\n",
      "4440/9600 [============>.................] - ETA: 53:16 - loss: 0.5659 - acc: 0.9148"
     ]
    }
   ],
   "source": [
    "history = model.fit([reviews_train, sum_train], \n",
    "                     target_train, \n",
    "                     epochs=EPOCHS,\n",
    "                     callbacks = [es],\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     validation_data=([reviews_test, sum_test], target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_source_word_index=r_tokenizer.index_word \n",
    "reverse_target_word_index=s_tokenizer.index_word \n",
    "target_word_index = s_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reverse_source_word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder inference\n",
    "inf_encoder_model = Model(inputs = encoder_inputs, outputs = [encoder_outputs, state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder inference\n",
    "\n",
    "# State of the previous time step\n",
    "decoder_state_input_h = Input(shape=(HIDDEN_UNITS,))\n",
    "decoder_state_input_c = Input(shape=(HIDDEN_UNITS,))\n",
    "# decoder_hidden_state_input = Input(shape=(max_reviews_seq_len, HIDDEN_UNITS))\n",
    "\n",
    "# Embeddings of the decoder sequence\n",
    "decoder_embeddings2 = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_LSTM(decoder_embeddings2, initial_state= [decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "# decoder_outputs, state_h, state_c = decoder_LSTM(decoder_embedding,  initial_state=decoder_state_inputs)\n",
    "# decoder_states = [state_h, state_c]\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# inf_decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = inf_encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # target_seq = np.array([0.0 for _ in range(max_reviews_seq_len)]).reshape(1, max_reviews_seq_len)\n",
    "\n",
    "    # Choose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "    \n",
    "#     target_seq = np.zeros((1, 1, max_summary_seq_len))\n",
    "#     target_seq[0, 0, target_word_index['start']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_word_index = np.argmax(output_tokens[0, -1, :])\n",
    "        # print(sampled_token_index)\n",
    "        # sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        # Want to get a default instead of a key error\n",
    "        sampled_word = reverse_target_word_index.get(sampled_word_index, \"NA\")\n",
    "        # print(sampled_token)\n",
    "        \n",
    "        # if(sampled_token!='end'):\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_word == 'end' or len(decoded_sentence.split()) > (max_summary_seq_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_word_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer sequence to words\n",
    "\n",
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2review(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reviews_test[:10])):\n",
    "    print(\"Review:\",seq2review(reviews_test[i]))\n",
    "    print()\n",
    "    print(\"Original summary:\",seq2summary(sum_test[i]))\n",
    "    print()\n",
    "    print(\"Predicted summary:\",decode_sequence(reviews_test[i].reshape(1, max_reviews_seq_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2review(reviews_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2summary(sum_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = inf_encoder_model.predict(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cardinality = 720\n",
    "# n_steps = 4\n",
    "# output = list()\n",
    "\n",
    "# target_seq = np.array([0.0 for _ in range(cardinality)]).reshape(1, cardinality)\n",
    "\n",
    "# yhat, h, c = inf_decoder_model.predict([target_seq] + state)\n",
    "# # store prediction\n",
    "# output.append(yhat[0,0,:])\n",
    "# # update state\n",
    "# state = [h, c]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lookup(tokenizer, vec, returnIntNotWord=True):\n",
    "#     twordkey = [(k, tokenizer.word_index[k]) for k in sorted(tokenizer.word_index, key=tokenizer.word_index.get, reverse=False)]\n",
    "#     oneHotVec = [] #captures the index of the ords\n",
    "#     engVec = [] #this one returns the indexs and the words. Make sure returnIntNotWord is false though\n",
    "#     for eachRow, notUsed in enumerate(vec):\n",
    "#         for index, item in enumerate(vec[0]):\n",
    "#             if vec[eachRow][index] == 1:\n",
    "#                 oneHotVec.append(index)\n",
    "#     for index in oneHotVec:\n",
    "#         engVec.append(twordkey[index])\n",
    "#     if returnIntNotWord == True:\n",
    "#         return oneHotVec\n",
    "#     else:\n",
    "#         return engVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = reviews_test[0].reshape(1, max_reviews_seq_len)\n",
    "input_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_out, e_h, e_c = inf_encoder_model.predict(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq = np.zeros((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq[0, 0] = target_word_index['start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens, h, c = decoder_model.predict([target_seq] + [e_h, e_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_token_index = np.argmax(output_tokens[0, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = output_tokens[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index.get(sampled_token_index, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq = np.zeros((1,1))\n",
    "target_seq[0, 0] = sampled_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_h, e_c = h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens, h, c = decoder_model.predict([target_seq] + [e_h, e_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "reverse_target_word_index.get(sampled_token_index, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
