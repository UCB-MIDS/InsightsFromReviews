{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File with the reviews database\n",
    "file = '/Users/gkhanna/Downloads/reviews_Home_and_Kitchen_5.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/gkhanna/Google Drive/210Capstone/code/InsightsFromReviews/app/ai',\n",
       " '/Users/gkhanna/anaconda3/lib/python37.zip',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/lib-dynload',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages/aeosa',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/gkhanna/.ipython']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\r\n",
      "Version: 1.14.0\r\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author: Google Inc.\r\n",
      "Author-email: packages@tensorflow.org\r\n",
      "License: Apache 2.0\r\n",
      "Location: /Users/gkhanna/anaconda3/lib/python3.7/site-packages\r\n",
      "Requires: astor, numpy, protobuf, gast, tensorboard, termcolor, google-pasta, grpcio, tensorflow-estimator, absl-py, wrapt, keras-preprocessing, wheel, six, keras-applications\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip3 show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages'\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/gkhanna/Google Drive/210Capstone/code/InsightsFromReviews/app/ai',\n",
       " '/Users/gkhanna/anaconda3/lib/python37.zip',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/lib-dynload',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages/aeosa',\n",
       " '/Users/gkhanna/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/gkhanna/.ipython',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gkhanna/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.tokens.span.Span size changed, may indicate binary incompatibility. Expected 72 from C header, got 80 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from insights import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insights import languageUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insights import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98400it [00:01, 78669.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 Reviews written to the dictionary \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load reviews into a dictionary\n",
    "file_d = features.loadFromDb(file, count = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(len(file_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewerID': 'APYOBQE6M18AA',\n",
       " 'asin': '0615391206',\n",
       " 'reviewerName': 'Martin Schwartz',\n",
       " 'helpful': [0, 0],\n",
       " 'reviewText': 'My daughter wanted this book and the price on Amazon was the best.  She has already tried one recipe a day after receiving the book.  She seems happy with it.',\n",
       " 'overall': 5.0,\n",
       " 'summary': 'Best Price',\n",
       " 'unixReviewTime': 1382140800,\n",
       " 'reviewTime': '10 19, 2013'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ASIN corresponding to the Iron Skillet\n",
    "# pl = 'B00006JSUA'\n",
    "# pl = 'B000QFDNP8'\n",
    "pl = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:08<00:00, 11174.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and Classified 100000 Reviews\n",
      "90259 Positive reviews\n",
      "9741 Negative reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_sent, reviews_pos_sent, reviews_neg_sent, sum_sent, sum_pos_sent, sum_neg_sent = summary.loadTolistsAndClassify(file_d, pl, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(sum_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_start_ not the best _end_'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_neg_sent[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'did not really care many of the cakes at all  not up to normal standing for wilton yearbooks of the past  the best cake is on the cover '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_neg_sent[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word counts in reviews and summaries\n",
    "We'll get another validation of this after tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_word_count = []\n",
    "sum_word_count = []\n",
    "\n",
    "for i in reviews_sent:\n",
    "      reviews_word_count.append(len(i.split()))\n",
    "\n",
    "for i in sum_sent:\n",
    "      sum_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'Reviews':reviews_word_count, 'summary':sum_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize: text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB_SIZE = 800\n",
    "# tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've already cleaned up the data\n",
    "# Though we could use this for cleaning also\n",
    "reviews_tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60875"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_tokenizer = Tokenizer()\n",
    "r_tokenizer.fit_on_texts(reviews_sent)\n",
    "reviews_sequences = r_tokenizer.texts_to_sequences(reviews_sent)\n",
    "reviews_word_index = r_tokenizer.word_index\n",
    "len(reviews_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14166"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_tokenizer = Tokenizer()\n",
    "s_tokenizer.fit_on_texts(sum_sent)\n",
    "summary_sequences = s_tokenizer.texts_to_sequences(sum_sent)\n",
    "sum_word_index = s_tokenizer.word_index\n",
    "len(sum_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60876"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_vocab_size = len(reviews_word_index) + 1\n",
    "reviews_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14167"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_vocab_size = len(sum_word_index) + 1\n",
    "sum_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max len of the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5294"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_reviews_seq_len = max([len(seq) for seq in reviews_sequences])\n",
    "max_reviews_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_summary_seq_len = max([len(seq) for seq in summary_sequences])\n",
    "max_summary_seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB_SIZE = len(reviews_word_index) - 10\n",
    "# VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_word_index_vsize = {}\n",
    "# counter = 0\n",
    "# for word in reviews_word_index.keys():\n",
    "#     if reviews_word_index[word] == 0:\n",
    "#         print(\"found 0!\")\n",
    "#         break\n",
    "#     if reviews_word_index[word] > VOCAB_SIZE:\n",
    "#         continue\n",
    "#     else:\n",
    "#         reviews_word_index_vsize[word] = reviews_word_index[word]\n",
    "#         counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(reviews_word_index_vsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_word_index_vsize = {}\n",
    "# counter = 0\n",
    "# for word in sum_word_index.keys():\n",
    "#     if sum_word_index[word] == 0:\n",
    "#         print(\"found 0!\")\n",
    "#         break\n",
    "#     if sum_word_index[word] > VOCAB_SIZE:\n",
    "#         continue\n",
    "#     else:\n",
    "#         sum_word_index_vsize[word] = sum_word_index[word]\n",
    "#         counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sum_word_index_vsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# MAX_LEN = max_reviews_seq_len\n",
    "pad_reviews_sequences = pad_sequences(reviews_sequences, maxlen=max_reviews_seq_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 5294\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_sequences[0]), len(pad_reviews_sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 17 807 266 ...   0   0   0]\n",
      " [  2  72   9 ...   0   0   0]\n",
      " [ 83   7  57 ...   0   0   0]\n",
      " ...\n",
      " [  2  73  77 ...   0   0   0]\n",
      " [  2  49 367 ...   0   0   0]\n",
      " [  9 232   7 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(pad_reviews_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 5294)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_reviews_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sum_sequences = pad_sequences(summary_sequences, maxlen=max_summary_seq_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 45\n"
     ]
    }
   ],
   "source": [
    "print(len(summary_sequences[0]), len(pad_sum_sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 45)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sum_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = np.zeros((num_samples, max_reviews_seq_len), dtype='float32')\n",
    "encoder_inputs.shape\n",
    "\n",
    "for i, seqs in enumerate(pad_reviews_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        encoder_inputs[i, j] = seq\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 5294)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder_inputs = np.zeros((num_samples, max_summary_seq_len), dtype='float32')\n",
    "decoder_inputs.shape\n",
    "        \n",
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        decoder_inputs[i, j] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 45)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 45, 14167)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs = np.zeros((num_samples, max_summary_seq_len, sum_vocab_size), dtype='float32')\n",
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        decoder_outputs[i, j, seq] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 45, 14167)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('/Users/gkhanna/Downloads/glove.6B/glove.6B.50d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix_creater(embedding_dimension, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dimension))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60876, 50)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_embedding_matrix = embedding_matrix_creater(50, word_index=reviews_word_index)\n",
    "reviews_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60876"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14167, 50)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_embedding_matrix = embedding_matrix_creater(50, word_index=sum_word_index)\n",
    "sum_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0728 22:54:13.777978 140735691277184 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0728 22:54:13.779467 140735691277184 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0728 22:54:13.797811 140735691277184 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as k\n",
    "k.clear_session()\n",
    "k.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import initializers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,LSTM,Dropout,Input,Activation,Add,concatenate, Embedding, RepeatVector\n",
    "from keras.layers.advanced_activations import LeakyReLU,PReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insights.attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "\n",
    "# MAX_LEN = 1000\n",
    "# VOCAB_SIZE = len(sum_embedding_matrix)\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_UNITS = 20\n",
    "# VOCAB_SIZE = VOCAB_SIZE + 1\n",
    "\n",
    "LEARNING_RATE = 0.002\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_embedding_layer = Embedding(input_dim = reviews_vocab_size, \n",
    "#                                     output_dim = EMBEDDING_DIM,\n",
    "#                                     input_length = max_reviews_seq_len,\n",
    "#                                     weights = [reviews_embedding_matrix],\n",
    "#                                     trainable = False)\n",
    "\n",
    "# decoder_embedding_layer = Embedding(input_dim = sum_vocab_size, \n",
    "#                                     output_dim = EMBEDDING_DIM,\n",
    "#                                     input_length = max_summary_seq_len,\n",
    "#                                     weights = [sum_embedding_matrix],\n",
    "#                                     trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_embedding_layer = Embedding(input_dim = reviews_vocab_size, \n",
    "                                    output_dim = EMBEDDING_DIM,\n",
    "                                    weights = [reviews_embedding_matrix],\n",
    "                                    trainable = False)\n",
    "\n",
    "decoder_embedding_layer = Embedding(input_dim = sum_vocab_size, \n",
    "                                    output_dim = EMBEDDING_DIM,\n",
    "                                    weights = [sum_embedding_matrix],\n",
    "                                    trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14167"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0728 22:54:13.856377 140735691277184 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0728 22:54:13.889212 140735691277184 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 5294)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5294, 50)     3043800     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 5294, 20), ( 5680        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 50)     708350      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 5294, 20), ( 3280        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 20), ( 5680        embedding_2[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 14167)  297507      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,064,297\n",
      "Trainable params: 4,064,297\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## # encoder\n",
    "encoder_inputs = Input(shape=(max_reviews_seq_len, ), dtype = 'int32',)\n",
    "encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "# LSTM 1\n",
    "encoder_LSTM1 = LSTM(HIDDEN_UNITS, return_sequences = True, return_state = True)\n",
    "encoder_output1, state_h1, state_c1 = encoder_LSTM1(encoder_embedding)\n",
    "\n",
    "# LSTM 2\n",
    "encoder_LSTM2 = LSTM(HIDDEN_UNITS, return_sequences = True, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder_LSTM2(encoder_output1)\n",
    "\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# decoder\n",
    "# decoder_inputs = Input(shape=(max_summary_seq_len, ), dtype = 'int32')\n",
    "decoder_inputs = Input(shape=(None, ), dtype = 'int32')\n",
    "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# Decoder LSTM with encoder_states as the initial state\n",
    "decoder_LSTM = LSTM(HIDDEN_UNITS, return_sequences = True, return_state = True)\n",
    "decoder_outputs, state_d_h, state_d_c = decoder_LSTM(decoder_embedding, initial_state = [state_h, state_c])\n",
    "\n",
    "# Dense Layer\n",
    "decoder_dense = TimeDistributed(Dense(units=sum_vocab_size, activation=\"softmax\"))\n",
    "decoder_outputs = decoder_dense(decoder_outputs) # SUM_VOCAB_SIZE, sum_embedding_matrix.shape[1]\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0728 22:54:15.841567 140735691277184 deprecation_wrapper.py:119] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(pad_sum_sequences)\n",
    "decoder_output_data = np.zeros((num_samples, max_summary_seq_len, sum_vocab_size), dtype=\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 45)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sum_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 45, 14167)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        if j > 0:\n",
    "            decoder_output_data[i][j][seq] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train, reviews_test, sum_train, sum_test = train_test_split(pad_reviews_sequences, pad_sum_sequences, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num = reviews_train.shape[0]\n",
    "train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 5294)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5294)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 45)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 45)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = decoder_output_data[:train_num]\n",
    "target_test = decoder_output_data[train_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 45, 14167)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 45, 14167)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 45, 14167)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0728 22:54:39.058580 140735691277184 deprecation.py:323] From /Users/gkhanna/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "  384/80000 [..............................] - ETA: 6:06:11 - loss: 9.2555 - acc: 0.7249"
     ]
    }
   ],
   "source": [
    "history = model.fit([reviews_train, sum_train], \n",
    "                     target_train, \n",
    "                     epochs=EPOCHS,\n",
    "                     callbacks = [es],\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     validation_data=([reviews_test, sum_test], target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_source_word_index=r_tokenizer.index_word \n",
    "reverse_target_word_index=s_tokenizer.index_word \n",
    "target_word_index = s_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reverse_source_word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder inference\n",
    "inf_encoder_model = Model(inputs = encoder_inputs, outputs = [encoder_outputs, state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder inference\n",
    "\n",
    "# State of the previous time step\n",
    "decoder_state_input_h = Input(shape=(HIDDEN_UNITS,))\n",
    "decoder_state_input_c = Input(shape=(HIDDEN_UNITS,))\n",
    "decoder_hidden_state_input = Input(shape=(max_reviews_seq_len, HIDDEN_UNITS))\n",
    "\n",
    "# Embeddings of the decoder sequence\n",
    "decoder_embeddings2 = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_LSTM(decoder_embeddings2, initial_state= [decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "# decoder_outputs, state_h, state_c = decoder_LSTM(decoder_embedding,  initial_state=decoder_state_inputs)\n",
    "# decoder_states = [state_h, state_c]\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# inf_decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = inf_encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # target_seq = np.array([0.0 for _ in range(max_reviews_seq_len)]).reshape(1, max_reviews_seq_len)\n",
    "\n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        print(sampled_token_index)\n",
    "        # sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        # Want to get a default instead of a key error\n",
    "        sampled_token = reverse_target_word_index.get(sampled_token_index, \"NA\")\n",
    "        print(sampled_token)\n",
    "        \n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_summary_seq_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer sequence to words\n",
    "\n",
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2review(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reviews_train[:5])):\n",
    "    print(\"Review:\",seq2review(reviews_test[i]))\n",
    "    print()\n",
    "    print(\"Original summary:\",seq2summary(sum_test[i]))\n",
    "    print()\n",
    "    print(\"Predicted summary:\",decode_sequence(reviews_test[i].reshape(1, max_reviews_seq_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = inf_encoder_model.predict(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cardinality = 720\n",
    "# n_steps = 4\n",
    "# output = list()\n",
    "\n",
    "# target_seq = np.array([0.0 for _ in range(cardinality)]).reshape(1, cardinality)\n",
    "\n",
    "# yhat, h, c = inf_decoder_model.predict([target_seq] + state)\n",
    "# # store prediction\n",
    "# output.append(yhat[0,0,:])\n",
    "# # update state\n",
    "# state = [h, c]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lookup(tokenizer, vec, returnIntNotWord=True):\n",
    "#     twordkey = [(k, tokenizer.word_index[k]) for k in sorted(tokenizer.word_index, key=tokenizer.word_index.get, reverse=False)]\n",
    "#     oneHotVec = [] #captures the index of the ords\n",
    "#     engVec = [] #this one returns the indexs and the words. Make sure returnIntNotWord is false though\n",
    "#     for eachRow, notUsed in enumerate(vec):\n",
    "#         for index, item in enumerate(vec[0]):\n",
    "#             if vec[eachRow][index] == 1:\n",
    "#                 oneHotVec.append(index)\n",
    "#     for index in oneHotVec:\n",
    "#         engVec.append(twordkey[index])\n",
    "#     if returnIntNotWord == True:\n",
    "#         return oneHotVec\n",
    "#     else:\n",
    "#         return engVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = reviews_test[0].reshape(1, max_reviews_seq_len)\n",
    "input_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_out, e_h, e_c = inf_encoder_model.predict(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq = np.array([0.0 for _ in range(max_reviews_seq_len)]).reshape(1, max_reviews_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq[0, 0] = target_word_index['start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens, h, c = decoder_model.predict([target_seq] + [e_h, e_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_token_index = np.argmax(output_tokens[0, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = output_tokens[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insights.attention import AttentionLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
